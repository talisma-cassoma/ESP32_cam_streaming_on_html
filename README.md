
# Dâ‰ˆOceanLab

authors:
Talisma Manuel<br>
model v0.1

<p align="center">
<img src="./assets/bg_cover_v2.png" title="underwater drone features" width="100%">
</p>

### Overview

This project is about an underwater drone equipped with intelligent computer vision capabilities. The drone is able to track objects autonomously, making it a valuable tool for various underwater applications.

 <p align="center">
    <img src="./assets/overview.png" title="D-OceanLab underwater design overview" width="90%"/>
  </p>
    
## Current features Stage

**Object Tracking**: A model for object tracking was trained, focusing on tracking fish. The training process utilized the [Roboflow Universe public Aquarium dataset](https://universe.roboflow.com/brad-dwyer/aquarium-combined). You can adapt this to your own dataset on Roboflow. This code resides within the repository.
<p align="center">
  <img src="https://blog.roboflow.com/content/images/2021/09/130703648-8af62801-d66c-41f5-80ae-889301ae9b44-1.gif" width="70%"/>
</p>
    
**Hand Gesture Recognition**: Another [Colab notebook](https://github.com/talisma-cassoma/HAND-GESTURES-DRIVE-ROBOT/blob/main/trainning.ipynb) explores hand gesture recognition, potentially for future drone control.

