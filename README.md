
# D≈OceanLab

authors:
Talisma Manuel<br>
model v0.1

<p align="center">



<img src="./assets/bg_cover_v2.png" title="underwater drone features" width="100%">
</p>

### Overview

This project is about an underwater drone equipped with intelligent computer vision capabilities. The drone is able to track objects autonomously, making it a valuable tool for various underwater applications.

 <p align="center">
    <img src="./assets/overview.png" title="D-OceanLab underwater design overview" width="90%"/>
  </p>

<div align="center">
<video src="https://github.com/user-attachments/assets/862fec10-1c0e-40ee-9b35-76949d90156e" controls high="200">
  your navegator do not suport embedded vídeos :(.
</video>
</div>

    
## Current features Stage

**Object Tracking**: A model for object tracking was trained, focusing on tracking fish. The training process utilized the [Roboflow Universe public Aquarium dataset](https://universe.roboflow.com/brad-dwyer/aquarium-combined). It can be adapted to an augmented custom dataset on Roboflow. This code resides within the repository.
<p align="center">
  <img src="https://blog.roboflow.com/content/images/2021/09/130703648-8af62801-d66c-41f5-80ae-889301ae9b44-1.gif" width="70%"/>
</p>
    
**Hand Gesture Recognition**: Another [Colab notebook](https://github.com/talisma-cassoma/HAND-GESTURES-DRIVE-ROBOT/blob/main/trainning.ipynb) explores hand gesture recognition, potentially for future drone control.

